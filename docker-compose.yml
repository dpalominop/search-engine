version: "3"

services:
  broker:
    container_name: celery-broker
    image: rabbitmq:management-alpine
    ports:
      - 8080:15672
      - 5672:5672
    restart: on-failure
    networks:
      search_engine_net:

  backend:
    container_name: celery-backend
    image: redis:6.2.4
    ports:
      - 6379:6379
    restart: on-failure
    networks:
      search_engine_net:
    command: redis-server --requirepass password
  
  elasticsearch:
    build:
      context: elasticsearch
      dockerfile: docker/Dockerfile
    image: "elasticsearch-logging:7.17.6"
    container_name: elasticsearch
    ports:
      - 9200:9200
    restart: on-failure
    volumes:
      - esdata:/usr/share/elasticsearch/data
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1024m -Xmx1024m"
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=changeme
    healthcheck:
        test: python3 logging-template.py || exit 1
        interval: 10s
        timeout: 1s
        retries: 10
    networks:
      search_engine_net:

  indexer:
    build:
      context: indexer
      dockerfile: docker/Dockerfile
      args:
        base_image_tag: "base-cpu-v1.13.2"
        base_image: "deepset/haystack"
    container_name: indexer
    env_file:
      - 'variables.env'
    restart: on-failure
    environment:
      - DOCUMENTSTORE_PARAMS_HOST=elasticsearch
      - DOCUMENTSTORE_PARAMS_USERNAME=elastic
      - DOCUMENTSTORE_PARAMS_PASSWORD=changeme
      - PIPELINE_YAML_PATH=/app/src/pipeline/pipelines_indexer.yml
      - BUCKET_NAME=document-datasets
    links:
      - backend:backend
      - broker:broker
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - search_engine_net

    command: celery worker -A src.worker.indexer -P threads --loglevel=INFO --queues=indexer

  api:
    build:
      context: api
      dockerfile: docker/Dockerfile.api
      args:
        base_image_tag: "base-cpu-v1.13.2"
        base_image: "deepset/haystack"
    container_name: api
    env_file:
      - 'variables.env'
    ports:
      - 8000:8000
    restart: on-failure
    environment:
      - DOCUMENTSTORE_PARAMS_HOST=elasticsearch
      - DOCUMENTSTORE_PARAMS_USERNAME=elastic
      - DOCUMENTSTORE_PARAMS_PASSWORD=changeme
      - PIPELINE_YAML_PATH=/app/src/pipeline/pipelines_retriever.yml
      - BUCKET_NAME=document-tasks
    links:
      - backend:backend
      - broker:broker
    healthcheck:
        test: curl --fail http://localhost:8000/health || exit 1
        interval: 30s
        timeout: 10s
        retries: 10
    networks:
      search_engine_net:
    depends_on:
      elasticsearch:
        condition: service_healthy

  ui:
    build:
      context: ui
      dockerfile: docker/Dockerfile
    container_name: ui
    ports:
      - 8501:8501
    restart: on-failure
    environment:
      - API_ENDPOINT=http://api:8000
      # The value fot the following variables will be read from the host, if present.
      # They can also be temporarily set for docker-compose, for example:
      # $ DISABLE_FILE_UPLOAD=1 DEFAULT_DOCS_FROM_RETRIEVER=5 docker-compose up
      - DISABLE_FILE_UPLOAD
      - DEFAULT_QUESTION_AT_STARTUP
      - DEFAULT_DOCS_FROM_RETRIEVER
      - DEFAULT_NUMBER_OF_ANSWERS
    command: "/bin/bash -c 'sleep 15 && python -m streamlit run src/webapp.py'"
    depends_on:
      api:
        condition: service_healthy
    networks:
      search_engine_net:

  localstack:
    image: localstack/localstack:1.4
    environment:
      SERVICES: s3
      DATA_DIR: /tmp/localstack/data
    volumes:
      - './data/documents:/tmp/localstack/dataset'
      - './localstack:/docker-entrypoint-initaws.d'
    container_name: localstack
    ports:
      - 4566:4566
    restart: on-failure
    networks:
      search_engine_net:

networks:
  search_engine_net:

volumes:
  esdata:
    driver: local
